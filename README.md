# YouWorker.AI

**Assistente conversazionale AI con interazione vocale e testuale, ricerca semantica e integrazione estensibile di strumenti.**

YouWorker.AI √® un'applicazione full-stack che combina tecnologie web moderne con modelli AI locali per offrire un'esperienza conversazionale potente e orientata alla privacy. Costruito con Next.js, FastAPI e il Model Context Protocol (MCP).

---

## ‚ú® Caratteristiche Principali

### üéôÔ∏è **Doppia Modalit√† di Interazione**
- **Modalit√† Testo**: Risposte in streaming real-time con Server-Sent Events
- **Modalit√† Voce**: Input vocale push-to-talk con riconoscimento e sintesi vocale italiana

### ü§ñ **Sistema Agente Intelligente**
- Alimentato da modelli Ollama locali (privacy-first, nessuna API esterna)
- Scoperta dinamica degli strumenti via Model Context Protocol (MCP)
- Architettura single-tool stepper per comportamento affidabile e prevedibile
- Risposte in streaming con feedback sull'esecuzione degli strumenti

### üìö **Gestione della Conoscenza**
- Ingestione documenti da file e URL
- Ricerca semantica con embedding vettoriali
- Supporto per PDF, file di testo e contenuti web
- Database vettoriale Qdrant per ricerca rapida per similarit√†

### üõ†Ô∏è **Sistema Strumenti Estensibile**
- **Ricerca Web**: Recupero e riassunto contenuti web in tempo reale
- **Query Semantica**: Recupero documenti RAG-powered
- **Data e Ora**: Operazioni calendario con timezone
- **Conversione Unit√†**: Calcoli quantit√† fisiche
- **Strumenti Personalizzati**: Facile integrazione via protocollo MCP

### üé® **UI/UX Moderna**
- Interfaccia pulita e responsive costruita con Next.js 15 e Tailwind CSS
- Visualizzazione real-time esecuzione strumenti
- Indicatori livello audio e controlli riproduzione
- Design mobile-friendly

---

## üöÄ Avvio Rapido

### Prerequisiti

- **Docker** e **Docker Compose** (consigliato)
- **GPU NVIDIA** (opzionale, per modelli accelerati)
- **Python 3.11+** e **Node.js 20+** (per sviluppo locale)

### Installazione con Docker (Consigliato)

1. **Clona il repository**:
   ```bash
   git clone <url-repository>
   cd youworker-fullstack
   ```

2. **Configura l'ambiente**:
   ```bash
   cp .env.example .env
   # Modifica .env con le tue preferenze
   ```

3. **Scarica i modelli TTS** (per modalit√† voce):
   ```bash
   ./ops/download-piper-models.sh
   ```

4. **Avvia tutti i servizi**:
   ```bash
   make compose-up
   ```

5. **Accedi all'applicazione**:
   - **Frontend**: http://localhost:8000
   - **API**: http://localhost:8001
   - **Documentazione API**: http://localhost:8001/docs

### Sequenza di Avvio

Lo stack Docker Compose avvia i servizi in questo ordine:

1. **PostgreSQL** - Storage sessioni e dati utente
2. **Qdrant** - Database vettoriale per ricerca semantica
3. **Ollama** - Server modelli linguistici locali
4. **Server MCP** - Fornitori di strumenti (web, semantic, datetime, ingest, units)
5. **API** - Backend FastAPI
6. **Frontend** - Applicazione web Next.js

**Il primo avvio pu√≤ richiedere 5-10 minuti** mentre Ollama scarica i modelli richiesti (gpt-oss, embeddinggemma).

---

## ‚öôÔ∏è Configurazione

### Variabili d'Ambiente Essenziali

| Variabile | Descrizione | Default |
|-----------|-------------|---------|
| `CHAT_MODEL` | Modello chat Ollama | `gpt-oss:latest` |
| `EMBED_MODEL` | Modello embedding | `embeddinggemma:300m` |
| `ROOT_API_KEY` | Chiave autenticazione API | `dev-root-key` |
| `OLLAMA_BASE_URL` | URL servizio Ollama | `http://ollama:11434` |
| `QDRANT_URL` | URL servizio Qdrant | `http://qdrant:6333` |
| `DATABASE_URL` | Connessione PostgreSQL | Auto-configurato |

### Configurazione Vocale

| Variabile | Descrizione | Default |
|-----------|-------------|---------|
| `STT_MODEL` | Dimensione modello Whisper | `small` |
| `STT_DEVICE` | Dispositivo compute | `cuda` |
| `STT_LANGUAGE` | Lingua riconoscimento vocale | `it` |
| `TTS_VOICE` | Modello voce Piper | `it_IT-paola-medium` |
| `TTS_PROVIDER` | Motore TTS | `piper` |

### Configurazione Frontend

| Variabile | Descrizione | Default |
|-----------|-------------|---------|
| `NEXT_PUBLIC_API_KEY` | Chiave API browser | Deve corrispondere a `ROOT_API_KEY` |
| `NEXT_PUBLIC_API_PORT` | Porta API | `8000` |

---

## üìñ Guida all'Uso

### Modalit√† Chat Testuale

1. Clicca il pulsante **"Testo"** nell'intestazione
2. Digita il tuo messaggio nel compositore
3. Premi Invio o clicca Invia
4. Osserva le risposte in streaming real-time e le esecuzioni degli strumenti

**Funzionalit√†**:
- Streaming token in tempo reale
- Visualizzazione esecuzione strumenti
- Risposte contestuali
- Riproduzione audio opzionale (attiva icona altoparlante)

### Modalit√† Voce

1. Clicca il pulsante **"Voce"** nell'intestazione
2. **Tieni premuto** il pulsante microfono e parla
3. **Rilascia** quando hai finito di parlare
4. Ascolta la risposta vocale dell'AI

**Funzionalit√†**:
- Registrazione push-to-talk
- Visualizzazione livello audio in tempo reale
- Trascrizione automatica italiana
- Risposte text-to-speech naturali

**Nota**: La modalit√† voce richiede HTTPS in produzione (i browser limitano l'accesso al microfono ai contesti sicuri). Usa `localhost` per lo sviluppo.

### Ingestione Documenti

1. Naviga alla pagina **Ingest**
2. Carica file o fornisci URL
3. Seleziona il tipo di documento (auto-rilevato per i file)
4. Clicca "Ingest" per elaborare

**Formati supportati**:
- Documenti PDF
- File di testo
- Pagine web (via URL)

---

## üõ†Ô∏è Strumenti Disponibili

### Ricerca Web
- `fetch_url`: Scarica e analizza pagine web
- `search_duckduckgo`: Cerca sul web
- `http_request`: Richieste HTTP personalizzate

### Query Semantica
- `semantic_search`: Trova documenti rilevanti per significato
- `list_collections`: Sfoglia collezioni documenti
- `get_collection_stats`: Visualizza metadati collezione

### Data e Ora
- `get_current_datetime`: Ottieni ora corrente in qualsiasi timezone
- `convert_timezone`: Converti tra timezone
- `calculate_time_difference`: Calcola differenze temporali

### Ingestione Documenti
- `ingest_file`: Carica ed elabora documenti
- `ingest_url`: Elabora contenuti web
- `list_ingested_documents`: Visualizza file elaborati

### Conversione Unit√†
- `convert_units`: Converti tra unit√† (lunghezza, massa, temperatura, ecc.)

---

## üß™ Sviluppo

### Setup Sviluppo Locale

#### Backend
```bash
# Crea ambiente virtuale
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Installa dipendenze
pip install -r requirements.txt

# Avvia server sviluppo
uvicorn apps.api.main:app --reload --port 8001
```

#### Frontend
```bash
cd apps/frontend

# Installa dipendenze
npm install

# Avvia server sviluppo
npm run dev
```

Accedi al server di sviluppo su http://localhost:3000

### Esecuzione Test

```bash
# Esegui tutti i test
pytest

# Esegui con coverage
pytest --cov=apps --cov=packages --cov-report=html

# Esegui suite test specifica
pytest tests/unit/
pytest tests/integration/
```

---

## üìÅ Struttura Progetto

```
youworker-fullstack/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ api/                    # Backend FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ frontend/               # Applicazione Next.js
‚îÇ   ‚îî‚îÄ‚îÄ mcp_servers/            # Servizi fornitori strumenti
‚îú‚îÄ‚îÄ packages/
‚îÇ   ‚îú‚îÄ‚îÄ agent/                  # Orchestrazione agente
‚îÇ   ‚îú‚îÄ‚îÄ llm/                    # Client Ollama
‚îÇ   ‚îú‚îÄ‚îÄ mcp/                    # Client protocollo MCP
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/              # Pipeline documenti
‚îÇ   ‚îú‚îÄ‚îÄ vectorstore/            # Wrapper Qdrant
‚îÇ   ‚îú‚îÄ‚îÄ db/                     # Modelli database
‚îÇ   ‚îî‚îÄ‚îÄ common/                 # Utility condivise
‚îú‚îÄ‚îÄ ops/
‚îÇ   ‚îú‚îÄ‚îÄ docker/                 # Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ compose/                # Configurazioni Docker Compose
‚îú‚îÄ‚îÄ docs/                       # Documentazione
‚îú‚îÄ‚îÄ tests/                      # Suite test
‚îî‚îÄ‚îÄ data/                       # Dati persistenti (git-ignored)
```

---

## üîí Sicurezza

- **Autenticazione API**: Tutti gli endpoint richiedono autenticazione con chiave API
- **Rate Limiting**: Limitazione integrata su endpoint sensibili
- **Validazione Input**: Validazione completa richieste con Pydantic
- **Configurazione CORS**: Whitelist origini stretta
- **Prevenzione SQL Injection**: Query parametrizzate via SQLAlchemy
- **Protezione Path Traversal**: Percorsi file validati
- **Gestione Segreti**: Configurazione basata su variabili d'ambiente

---

## ü§ù Contribuire

Leggi [CONTRIBUTING.md](CONTRIBUTING.md) per le linee guida.

### Flusso di Lavoro Sviluppo

1. Crea un branch per la funzionalit√†
2. Apporta le modifiche e aggiungi test
3. Esegui la suite di test (`pytest`)
4. Esegui il commit delle modifiche
5. Apri una Pull Request

---

## üìÑ Licenza

Questo progetto √® concesso in licenza MIT - vedi il file [LICENSE](LICENSE) per i dettagli.

---

## üôè Ringraziamenti

- **Ollama** - Hosting LLM locale
- **Piper TTS** - Sintesi vocale di alta qualit√†
- **Faster Whisper** - Riconoscimento vocale efficiente
- **Model Context Protocol** - Framework integrazione strumenti
- **Qdrant** - Ricerca similarit√† vettoriale
- **Next.js** - Framework React
- **FastAPI** - Framework web Python moderno

---

**Costruito con ‚ù§Ô∏è dal team YouWorker.AI**
