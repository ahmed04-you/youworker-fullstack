x-ollama-gpu-deploy: &ollama-gpu-deploy
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [gpu]

x-ollama-gpu-env: &ollama-gpu-env
  NVIDIA_VISIBLE_DEVICES: "all"
  NVIDIA_DRIVER_CAPABILITIES: "compute,utility"

services:
  postgres:
    image: postgres:15
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-youworker}
    ports:
      - "5432:5432"
    volumes:
      - ../../data/postgres:/var/lib/postgresql/data
  qdrant:
    image: qdrant/qdrant:latest
    restart: unless-stopped
    ports:
      - "6333:6333"
    volumes:
      - ../../data/qdrant:/qdrant/storage

  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "11434:11434"
    deploy: *ollama-gpu-deploy
    volumes:
      - ../../data/ollama:/root/.ollama
    environment:
      <<: *ollama-gpu-env

  mcp_web:
    build:
      context: ../..
      dockerfile: ops/docker/Dockerfile.mcp_web
    command: ["uvicorn", "apps.mcp_servers.web.server:app", "--host", "0.0.0.0", "--port", "7001"]
    restart: unless-stopped
    ports:
      - "7001:7001"

  mcp_semantic:
    build:
      context: ../..
      dockerfile: ops/docker/Dockerfile.mcp_semantic
    command: ["uvicorn", "apps.mcp_servers.semantic.server:app", "--host", "0.0.0.0", "--port", "7002"]
    restart: unless-stopped
    ports:
      - "7002:7002"
    depends_on:
      - qdrant
      - ollama

  mcp_datetime:
    build:
      context: ../..
      dockerfile: ops/docker/Dockerfile.mcp_datetime
    command: ["uvicorn", "apps.mcp_servers.datetime.server:app", "--host", "0.0.0.0", "--port", "7003"]
    restart: unless-stopped
    ports:
      - "7003:7003"

  mcp_ingest:
    build:
      context: ../..
      dockerfile: ops/docker/Dockerfile.mcp_ingest
    command: ["uvicorn", "apps.mcp_servers.ingest.server:app", "--host", "0.0.0.0", "--port", "7004"]
    restart: unless-stopped
    ports:
      - "7004:7004"
    depends_on:
      - qdrant
      - ollama
      - postgres
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql+asyncpg://postgres:postgres@postgres:5432/youworker}
      QDRANT_URL: http://qdrant:6333
      OLLAMA_BASE_URL: http://ollama:11434

  mcp_units:
    build:
      context: ../..
      dockerfile: ops/docker/Dockerfile.mcp_units
    command: ["uvicorn", "apps.mcp_servers.units.server:app", "--host", "0.0.0.0", "--port", "7005"]
    restart: unless-stopped
    ports:
      - "7005:7005"

  api:
    build:
      context: ../..
      dockerfile: ops/docker/Dockerfile.api
      args:
        ENABLE_GPU_TORCH: ${ENABLE_GPU_TORCH:-0}
    environment:
      <<: *ollama-gpu-env
      APP_ENV: production
      API_PORT: 8001
      FRONTEND_ORIGIN: ${FRONTEND_ORIGIN:-http://localhost:8000,http://127.0.0.1:8000}
      OLLAMA_BASE_URL: http://ollama:11434
      CHAT_MODEL: gpt-oss:latest
      EMBED_MODEL: embeddinggemma:300m
      QDRANT_URL: http://qdrant:6333
      DATABASE_URL: ${DATABASE_URL:-postgresql+asyncpg://postgres:postgres@postgres:5432/youworker}
      ROOT_API_KEY: ${ROOT_API_KEY:-dev-root-key}
      MCP_SERVER_URLS: http://mcp_web:7001,http://mcp_semantic:7002,http://mcp_datetime:7003,http://mcp_ingest:7004,http://mcp_units:7005
      INGEST_ACCELERATOR: ${INGEST_ACCELERATOR:-auto}
      INGEST_GPU_DEVICE: ${INGEST_GPU_DEVICE:-cuda}
    restart: unless-stopped
    deploy: *ollama-gpu-deploy
    gpus: "all"
    ports:
      - "8001:8001"
    volumes:
      - ../../examples/ingestion:/data/examples:ro
      - ../../data/uploads:/data/uploads
    depends_on:
      ollama:
        condition: service_started
      qdrant:
        condition: service_started
      postgres:
        condition: service_started
      mcp_web:
        condition: service_started
      mcp_semantic:
        condition: service_started
      mcp_datetime:
        condition: service_started
      mcp_ingest:
        condition: service_started
      mcp_units:
        condition: service_started

  frontend:
    build:
      context: ../..
      dockerfile: ops/docker/Dockerfile.frontend
      args:
        NEXT_PUBLIC_API_BASE_URL: ${NEXT_PUBLIC_API_BASE_URL:-}
        NEXT_PUBLIC_API_PORT: ${NEXT_PUBLIC_API_PORT:-8001}
        NEXT_PUBLIC_API_KEY: ${NEXT_PUBLIC_API_KEY:-dev-root-key}
    environment:
      NEXT_INTERNAL_API_BASE_URL: http://api:8001
      NEXT_PUBLIC_API_KEY: ${NEXT_PUBLIC_API_KEY:-dev-root-key}
    restart: unless-stopped
    ports:
      - "8000:3000"
    depends_on:
      api:
        condition: service_started
